{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 dst  \\\n",
      "0                                      - Intriguing.   \n",
      "1  He would need to repeat his vows in the land o...   \n",
      "2                 You couldn't even answer my texts?   \n",
      "3                                How fast do you go?   \n",
      "4  He's talking about a few right here in Lisbon,...   \n",
      "\n",
      "                                                 src  \n",
      "0                                  ◄▴◓◠▨ ◨▽◠▦◈◬◓▪▼◬▵  \n",
      "1  ▽◪◎◗▦◫▦◫ ▫▴▨◓◠◓ ▴▫◎◪▱◫ ◚▴ ◞◧▦◞▾▢▱◨▨ ◒◠◓◠◀▪▦◈◠▦...  \n",
      "2               ◄▴◞◠▸▱◠◓▪◎◠ ◀◫▱◪ ▼◪◚◠▻ ◚▴◓▴◎◪◈◗▦ ◎◫?  \n",
      "3                    ▯◪ ▨◠◈◠◓ ◞◭◓◠▫ ◳◠▻◬◳◧◓ ◞▴▦◗▦▨◫?  \n",
      "4  ◈◠ ◧▱◠▦ ◀◫◓ ▨◠◉ ◂▱◠▽◈◠▦ ◀◠▷◞◪◈◗◳◧◓■ ◉◧◐▾▦▱◨◐▾ ...  \n",
      "                                                 dst  \\\n",
      "0  The hosts regrouped, and Bouchard evened the s...   \n",
      "1  A new cancer vaccine may teach the immune syst...   \n",
      "2  Currently, language subjects are as popular as...   \n",
      "3  It's no surprise that restaurant chains contin...   \n",
      "4  Sales of drinks in pubs and bars increased by ...   \n",
      "\n",
      "                                                 src  \n",
      "0  ◘◚ ◞◠▷◫◀◗ ▫◠▨◬◎ ▨◪▦◈◫▦◫ ▫◧▻▱◠◈▪ ◚◪ ◝◂▾▼▷◠◓◈'◬▦...  \n",
      "1  ◤◪▦◫ ▨◠▦◞▴◓ ◠◒▪◞▪■ ◀◠◐▪◒◬▨▱▪▨ ◞◫◞▫◪◎◫▦▴ ▨◣▫◭ ▦...  \n",
      "2  ▮◪◉◎▴▱◫ ◈◪◓◞▱◪◓ ◧▱◠▦ ◈◗▱ ◈◪◓◞▱◪◓◗■ ◠◓▫▪▨ ◀◠◐◬◎...  \n",
      "3  ▤▴◞▫◂◓◠▦ ◕◓▾▻▱◠◓▪▦▪▦■ ◞◠▫▪◒▱◠◓◈◠ ◀◗◓ ◣▦▼◪▨◗ ◳▪...  \n",
      "4  ◲◒▱▴▫◗▱◪▦ ▻▾◀ ◚◪ ◀◠◓▱◠◓◈◠ ◀◨ ◠◳ ◳◫◳▴▼◪▨ ◞◠▫◬◒▱...  \n",
      "                                                 src\n",
      "0  ◲▦◠▦◬▦■ ◉◗▢◕◗ ◍◗▱◎ ▽◠▽▪▦◠ ◕▴◉◗▦▼▴ ◀◗◓◉◧▨ ◎▴◞◠▸...\n",
      "1  ▯▴▥ ◟◧◓▨▱◨ ◀◫◓ ◈◠◈◬■ ◉◂▼◨◐◨▦ ◠▦▦◪◞◗▦◗▦ ▽◠▢◈◬◐▪...\n",
      "2  ◡◠▻◧▦ ◂▫◧◎◂◀◗▱ ◍◗◓◎◠◞◬ ◠▦▱◠◒◎◠◞▪▢ ◝◓▴▹◗▫ ◈◨◓▾◎...\n",
      "3  ◝▾◀◀◠ ▰◠▫◞◂▦ ◚▴ ▰▴◀◀ ▮◫◎▻◞◂▦■ ◞◠◀◠▷ ◂◳▦◠▦◠▦ ◍◂...\n",
      "4  \"○◐▱◠◈◬◐▪▦▪ ◕◣◓◎◪▱◪◓◗▦◪ ◠◞▱◠ ◗▢◫▦ ◚▴◓◎▴■\" ◈◪◈◫...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Определяем путь к папке\n",
    "base_path = '/Users/osintsev/Study/YandexML/3/ml_trainings.alien_translation'\n",
    "\n",
    "# Полные пути к файлам\n",
    "train_path = os.path.join(base_path, 'train')\n",
    "val_path = os.path.join(base_path, 'val')\n",
    "test_path = os.path.join(base_path, 'test_no_reference')\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_json(train_path, lines=True)\n",
    "val_data = pd.read_json(val_path, lines=True)\n",
    "test_data = pd.read_json(test_path, lines=True)\n",
    "\n",
    "# Проверка загруженных данных\n",
    "print(train_data.head())\n",
    "print(val_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "def build_vocab(data, tokenizer, specials=[\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]):\n",
    "    counter = Counter(chain(*[tokenizer(text) for text in data]))\n",
    "    vocab = {token: idx for idx, token in enumerate(specials)}\n",
    "    for token in counter.keys():\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_src = build_vocab(train_data['src'].to_list(), simple_tokenizer)\n",
    "vocab_dst = build_vocab(train_data['dst'].to_list(), simple_tokenizer)\n",
    "\n",
    "\n",
    "def tokenize(text, vocab, tokenizer):\n",
    "    return [vocab.get(\"<sos>\")] + [vocab.get(token, vocab.get(\"<unk>\")) for token in text] + [vocab.get(\"<eos>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, vocab_src, vocab_dst, tokenizer_src, mode='train'):\n",
    "        self.vocab_src = vocab_src\n",
    "        self.vocab_dst = vocab_dst\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.df) \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src_text = self.df.loc[index]['src']\n",
    "        src = tokenize(src_text, self.vocab_src, self.tokenizer_src)\n",
    "\n",
    "        if mode == 'train':\n",
    "            dst_text = self.df.loc[index]['dst']\n",
    "            dst = tokenize(dst_text, self.vocab_src, self.tokenizer_src)\n",
    "            return torch.tensor(src), torch.tensor(dst)\n",
    "        else:\n",
    "            return torch.tensor(src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, batch_first=False, padding_value=vocab_src[\"<pad>\"])\n",
    "    trg_batch = pad_sequence(trg_batch, batch_first=False, padding_value=vocab_dst[\"<pad>\"])\n",
    "    return src_batch, trg_batch \n",
    "\n",
    "\n",
    "train_dataset = CustomData(train_data, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "new_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
